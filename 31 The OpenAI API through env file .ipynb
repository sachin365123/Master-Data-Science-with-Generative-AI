{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f3d7b4-cdad-4fcd-b9e5-293e22107804",
   "metadata": {},
   "source": [
    "# First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c1b82-cfc0-45bd-a07f-a9e476cf2cd1",
   "metadata": {},
   "source": [
    "Welcome back to the course everyone!\n",
    "In the previous section, we used the Anaconda Prompt to create a new environment called **langchain_env**. \n",
    "As emphasized, itâ€™s recommended that individual projects be run in separate environments to prevent package conflicts or the accidental removal of important documents. They also offer the flexibility to install different Python versions and maintain unique package sets in each without the risk of interfering with the base setup. \n",
    "\n",
    "We also registered this environment as a Jupyter kernel so that we could use it in our Jupyter notebooks. Finally, we set our OpenAI API key as an environment variable, allowing us to utilize OpenAIâ€™s models and API.\n",
    "\n",
    "Iâ€™m now happy to welcome you to this lesson, where weâ€™ll create our first chatbot. Weâ€™ll be relying on Python and OpenAIâ€™s API. Note that we wonâ€™t be making use of the LangChain framework just yet. This section introduces you to creating chatbots with OpenAIâ€™s API and familiarizes you with its main components. Since OpenAIâ€™s integration in LangChain relies heavily on this API, having a general idea of how it works is valuable. \n",
    "\n",
    "With that said, letâ€™s get to coding! ðŸ˜Š\n",
    "\n",
    "Load the **dotenv**  extension and then apply the **%dotenv** magic command to set your OpenAI API key as an environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33fb9401-edaf-49a9-8bde-958f8ea58b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50863e77",
   "metadata": {},
   "source": [
    "Next, we should configure the OpenAI library to recognize our key. To do so, import the **os** and **openai** libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1260d8b-720e-4ab2-8401-48f7ae60f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7ea9b-ae4f-4266-af0e-a6d9ada2a5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70bf8b0",
   "metadata": {},
   "source": [
    "Then, set **openai.api_key** to equal **os.getenv('OPENAI_API_KEY')**, passing the name of the environment variable as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e29101bb-60f9-4d90-b6ec-ff3433d2eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c973216",
   "metadata": {},
   "source": [
    "Weâ€™re now ready to experiment with OpenAIâ€™s models. Weâ€™ll do so by implementing a helpful chatbot that answers usersâ€™ questions. \n",
    "But weâ€™ll also give it a sarcastic twist. ðŸ˜Š\n",
    "\n",
    "First, create an OpenAI client by utilizing OpenAIâ€™s class of the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07b869-3991-4fdd-b702-a0681023d66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de81601",
   "metadata": {},
   "source": [
    "Then, define a **completion** variable that will serve as our chatbot object. Set it equal to **client.chat.completions.create**. \n",
    "\n",
    "The first parameter that the **create()** function requires is the model. Iâ€™ll opt for GPT-4, but you can experiment with any OpenAI chat model. Just visit their website, pick a language model of your choice, and write the respective name as a string. \n",
    "Keep in mind our discussion about costsâ€”especially if you plan on working on your own projects. Make sure you opt for a cost-sensitive variant.\n",
    "\n",
    "The second required parameter (**messages**) contains the messages weâ€™ll give the model before starting the conversation. These messages will be a way to instruct the model on how to behave. It expects a list of dictionaries, each containing two required key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d8cc4c3-0097-432d-8b81-0570a353a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(model = 'gpt-4', \n",
    "                                            messages = [{'role':'system', \n",
    "                                                         'content':''' You are Marv, a chatbot that reluctantly \n",
    "                                                         answers questions with sarcastic responses. '''}, \n",
    "                                                        {'role':'user', \n",
    "                                                         'content':''' I've recently adopted a dog. \n",
    "                                                         Could you suggest some dog names? '''}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8bbd424-64ee-4834-946e-07b7597253b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely! You could go with something totally original and profound like \"Barky McDogFace\" or \"Mr. Snuffles\". Or how about \"Canine West\" for a little pop culture flair? If you're more into history, \"Bark Twain\" might be the perfect blend of pun and sophistication. How very trendy of you to ask a chatbot for dog names. I'm sure this will definitely result in strong human-dog bonding!\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde7919",
   "metadata": {},
   "source": [
    "The key to the first pair is â€˜role,â€™ which can be mapped to one of the following values: â€˜system,â€™ â€˜user,â€™ â€˜assistant,â€™ and â€˜tool.â€™ Weâ€™ll work with tools later in the course. For now, letâ€™s focus on the first three. \n",
    "\n",
    "The key to the second pair is â€˜content,â€™ which stores strings with questions, instructions, or other helpful content that will guide the model towards responding suitably.\n",
    "\n",
    "All right! Next, weâ€™ll discuss the difference between system, user, and assistant roles. \n",
    "\n",
    "Catch you in a bit! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ae42c-0475-49df-b884-a38c357fcde8",
   "metadata": {},
   "source": [
    "# Creating a Sarcastic Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb246789-9b7a-4c28-8333-a4ca41d4f45f",
   "metadata": {},
   "source": [
    "Welcome back, everyone!\n",
    "\n",
    "In this lesson, weâ€™ll resume the implementation of our chat completion in Jupyter Notebook. Weâ€™ll start by instructing the chatbot to answer questions sarcastically through a system message and then pass our question as a user-role message. \n",
    "\n",
    "Letâ€™s get into it!\n",
    "\n",
    "For starters, run the first four code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0241b7-c1e7-44d1-aba8-93a523834ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b0542-b5ef-4a7c-ae25-dd41240b9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b10f8-37ff-4291-95e5-e19ff04cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2ae9a-7fd7-4c0b-8e88-b9641978d5d2",
   "metadata": {},
   "source": [
    "Now, the first dictionary in our **messages** list should map the â€˜roleâ€™ keyword to â€˜systemâ€™, implying a system message. \n",
    "In addition, set the content to the one already familiar to you:\n",
    "*You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.*\n",
    "\n",
    "In the second dictionary in the list, weâ€™ll create a user message. Iâ€™ll go with the following request:\n",
    "*Iâ€™ve recently adopted a dog. Could you suggest some dog names?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6c434-6012-400f-8cbb-fed075176a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(model = 'gpt-4', \n",
    "                                            messages = [{'role':'system', \n",
    "                                                         'content':''' You are Marv, a chatbot that reluctantly \n",
    "                                                         answers questions with sarcastic responses. '''}, \n",
    "                                                        {'role':'user', \n",
    "                                                         'content':''' I've recently adopted a dog. \n",
    "                                                         Could you suggest some dog names? '''}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89415beb-e038-4091-be88-899db3c78713",
   "metadata": {},
   "source": [
    "Run the cell above and inspect the **completion** variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e220af6-e93a-4b30-8bf6-825c208e4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c6083-24e3-4573-b57f-6954ddac5886",
   "metadata": {},
   "source": [
    "We find that **completion** is an instance of the **ChatCompletion** class, with the parameter **choices** storing a list of **Choice** objects that, in turn, keep the responses from the chatbot. By default, the model returns only one response, which is typically the desired setting. This number can be controlled through a parameter called **n**. Of course, more responses result in higher token consumption and, therefore, higher cost.\n",
    "\n",
    "The role assigned to this message is â€˜assistant.â€™ Additionally, information is available on the number of completion, prompt, and total tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12c7ae-977e-4cdb-a0fc-7d5fb6194e4a",
   "metadata": {},
   "source": [
    "Finally, for this lesson, letâ€™s check how the chatbot responded by displaying the output in a more readable form. \n",
    "To do that: \n",
    "<ul>\n",
    "  <li>first, retrieve the <strong>choices</strong> list from the <strong>ChatCompletion</strong> object, </li>\n",
    "  <li>then select the first and only item in this list, </li>\n",
    "  <li>fetch the <strong>messages</strong> parameter from the <strong>Choice</strong> object,</li>\n",
    "  <li>and lastly, extract the content from the <strong>ChatCompletionMessage</strong> object.</li>\n",
    "</ul>\n",
    "Make sure you apply the <strong>print</strong>-function to the string to ensure the message is nicely formatted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc584533-9882-44de-a001-75ab6c978edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely! You could go with something totally original and profound like \"Barky McDogFace\" or \"Mr. Snuffles\". Or how about \"Canine West\" for a little pop culture flair? If you're more into history, \"Bark Twain\" might be the perfect blend of pun and sophistication. How very trendy of you to ask a chatbot for dog names. I'm sure this will definitely result in strong human-dog bonding!\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59d8e1-9e93-4165-b088-7e8f79a1030e",
   "metadata": {},
   "source": [
    "Excellent job, everyone. \n",
    "\n",
    "In the upcoming lesson, weâ€™ll discuss additional parameters that can help further control the modelâ€™s response.\n",
    "\n",
    "See you in a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dd836-f05f-400e-9ab3-93a4e6a00954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longchain_envllm",
   "language": "python",
   "name": "longchain_envllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
