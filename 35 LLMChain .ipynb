{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda61eda",
   "metadata": {},
   "source": [
    "# Prompt Templates and Prompt Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c94c7c-6f19-4ca2-88e9-875cf6db7f37",
   "metadata": {},
   "source": [
    "###### Mastering LangChain: ChatOpenAI Model IO in Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ada85-72a8-4ddb-96fb-448a9ea41b8d",
   "metadata": {},
   "source": [
    "###### Run the line of code below to check the version of langchain in the current environment.\n",
    "###### Substitute \"langchain\" with any other package name to check their version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda31586-1dee-4cb6-bae7-42f46c1930f2",
   "metadata": {},
   "source": [
    "#### ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878e3d3-37d4-46c8-82fa-188b7b1603bf",
   "metadata": {},
   "source": [
    "# LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cd8f1-043d-420f-99f6-1802d6641c29",
   "metadata": {},
   "source": [
    "##### So far, we've solidified our knowledge of model inputs and outputs in long chain.\n",
    "##### This foundation is essential because structuring a good prompt is integral to developing a good chatbot.\n",
    "##### In this lesson, we'll introduce the most straightforward chain class the LLM chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1d6a103-51a7-48a1-83d0-c19bde4aeae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts import (ChatPromptTemplate,\n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    AIMessagePromptTemplate, \n",
    "                                    FewShotChatMessagePromptTemplate)\n",
    "\n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a569fff-1ece-49f1-bf03-07490044141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\longchain_envllm\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f4b7f5c-dd94-4eab-8d55-80b6ffd6a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_H = '''I've recently planning to switch {IT_company}. \n",
    "Could you suggest some {IT_company} names?'''\n",
    "TEMPLATE_AI = '''{response}'''\n",
    "\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)\n",
    "message_template_ai = AIMessagePromptTemplate.from_template(template = TEMPLATE_AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a42fec38-1b29-40e6-ab49-6896ae724a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = ChatPromptTemplate.from_messages([message_template_h, \n",
    "                                                     message_template_ai])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbe805ad-a236-40f0-848c-3d582e902b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [{'IT_company':'it', \n",
    "             'response':'''Oh, absolutely. Because nothing screams \"I'm a responsible recruitment team\" \n",
    "like asking a chatbot to name your new job. How about \"Prompt Engineer\" (if it's a literary AI related)? '''}, \n",
    "            \n",
    "            {'IT_company':'non-it', \n",
    "             'response':'''Oh, absolutely. Because nothing screams \"I'm a unique and creative recruitment team member\" \n",
    "             like asking a chatbot to name your non-it job. How about \"Data Entry Person\", \"Hardware Repair Man\", or \"Mobile Opererator\"? '''}, \n",
    "            \n",
    "            {'IT_company':'commerce', \n",
    "             'response':\n",
    "             '''Oh, absolutely. Because nothing screams \"I'm a fun and quirky recruitment team member\" \n",
    "             like asking a chatbot to name your commerce job. How about \"Policy Developer\", \"Economic Development Coordinator\", or \"Training Developer\"?'''}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60de4cad-2d8f-4f76-812a-1b73b40cf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(examples = examples, \n",
    "                                                   example_prompt = example_template, \n",
    "                                                   input_variables = ['IT_company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66b9f8f0-8fc6-4dbb-bb3d-b9a0974d7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([few_shot_prompt, \n",
    "                                                  message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f0ae83d-c197-4ec2-848b-3a7a0e141ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_5712\\2633328307.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm = chat,\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm = chat, \n",
    "                 prompt = chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ad86a6-0c89-4228-8532-e881f10519b8",
   "metadata": {},
   "source": [
    "##### Here, LLMChain is used to create a chain that connects an llm (language model) with a prompt.\n",
    "##### chat_template is a pre-defined prompt template that the model will use as input when generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d36d0ca-92ad-4e52-804c-f9c6b258973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'IT_company':'non-it'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a044ee6d-a8f8-4d39-befb-560663796739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT_company': 'non-it',\n",
       " 'text': 'Sure, here are some non-IT job titles you might consider:\\n\\n1. Operations Manager\\n2. Business Analyst\\n3. Marketing Specialist\\n4. Sales Representative\\n5. Human Resources Specialist\\n6. Financial Analyst\\n7. Project Manager\\n8. Product Manager\\n9. Supply Chain Analyst\\n10. Quality Assurance Specialist\\n11. Customer Service Representative\\n12. Public Relations Specialist\\n13. Event Planner\\n14. Administrative Assistant\\n15. Graphic Designer\\n\\nRemember, the best job title'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68243147-5dd5-45b4-b254-4419ef4d1024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some non-IT job titles you might consider:\n",
      "\n",
      "1. Operations Manager\n",
      "2. Business Analyst\n",
      "3. Marketing Specialist\n",
      "4. Sales Representative\n",
      "5. Human Resources Specialist\n",
      "6. Financial Analyst\n",
      "7. Project Manager\n",
      "8. Product Manager\n",
      "9. Supply Chain Analyst\n",
      "10. Quality Assurance Specialist\n",
      "11. Customer Service Representative\n",
      "12. Public Relations Specialist\n",
      "13. Event Planner\n",
      "14. Administrative Assistant\n",
      "15. Graphic Designer\n",
      "\n",
      "Remember, the best job title\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779da46f-0790-4c2f-8242-53a84b0f01b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longchain_envllm",
   "language": "python",
   "name": "longchain_envllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
